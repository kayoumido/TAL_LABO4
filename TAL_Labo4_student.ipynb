{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c7/HEIG-VD_Logo_96x29_RVB_ROUGE.png\" alt=\"HEIG-VD Logo\" width=\"250\"/>\n",
    "\n",
    "# Cours TAL - Laboratoire 4\n",
    "# Reconnaissance d'entités nommées (NER)\n",
    "\n",
    "**Objectifs**\n",
    "\n",
    "Appliquer l'outil de *Named Entity Recognition* fourni par NLTK sur le corpus Reuters en anglais, puis évaluer sa performance sur les données de test CoNLL 2003 possédant une annotation de référence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Expériences avec la NER de NLTK\n",
    "\n",
    "Le **but de cette partie** est d'utiliser le reconnaisseur d'entités nommées de NLTK pour extraire les entités nommées les plus fréquentes du corpus Reuters, avec leur type.\n",
    "* le NER de NLTK est tout simplement la fonction `nltk.ne_chunk`, qui s'applique sur un texte tokenisé, avec les POS tags -- la fonction est documentée dans le [livre NLTK, ch.7](http://www.nltk.org/book/ch07.html), section 5 (tout à la fin) ;\n",
    "*  le corpus Reuters contient environ 10'000 dépêches datant des années 1980, et il est fourni avec NLTK comme expliqué dans le [livre NLTK, ch.2](http://www.nltk.org/book/ch02.html), §1.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "#nltk.downloader.Downloader().download('reuters') \n",
    "#nltk.download('maxent_ne_chunker')\n",
    "#nltk.download('words')\n",
    "# à exécuter une seule fois pour télécharger les fichiers localement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En suivant les exemples fournis dans le livre NLTK, veuillez écrire le code qui permet de répondre aux questions suivantes, et écrire vos réponses dans une cellule *text markdown* ensuite.\n",
    "* Combien de fichiers (`fileids`) le corpus Reuters contient-il ?\n",
    "* Combien de phrases le corpus contient-il ?  (note : un seul appel de fonction est nécessaire)\n",
    "* Combien de mots le corpus contient-il ?  (note : un seul appel de fonction est nécessaire)\n",
    "* Veuillez afficher 5 *fileids* de votre choix (les noms, pas les contenus)\n",
    "* Pour un fichier (*fileid*) de votre choix, veuillez afficher son texte brut, puis la liste de ses phrases, puis enfin la liste de ses mots (avec la tokenization de référence du corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fileid \"test/14840\" raw text\n",
      "INDONESIAN COMMODITY EXCHANGE MAY EXPAND\n",
      "  The Indonesian Commodity Exchange is\n",
      "  likely to start trading in at least one new commodity, and\n",
      "  possibly two, during calendar 1987, exchange chairman Paian\n",
      "  Nainggolan said.\n",
      "      He told Reuters in a telephone interview that trading in\n",
      "  palm oil, sawn timber, pepper or tobacco was being considered.\n",
      "      Trading in either crude palm oil (CPO) or refined palm oil\n",
      "  may also be introduced. But he said the question was still\n",
      "  being considered by Trade Minister Rachmat Saleh and no\n",
      "  decision on when to go ahead had been made.\n",
      "      The fledgling exchange currently trades coffee and rubber\n",
      "  physicals on an open outcry system four days a week.\n",
      "      \"Several factors make us move cautiously,\" Nainggolan said.\n",
      "  \"We want to move slowly and safely so that we do not make a\n",
      "  mistake and undermine confidence in the exchange.\"\n",
      "      Physical rubber trading was launched in 1985, with coffee\n",
      "  added in January 1986. Rubber contracts are traded FOB, up to\n",
      "  five months forward. Robusta coffee grades four and five are\n",
      "  traded for prompt delivery and up to five months forward,\n",
      "  exchange officials said.\n",
      "      The trade ministry and exchange board are considering the\n",
      "  introduction of futures trading later for rubber, but one\n",
      "  official said a feasibility study was needed first. No\n",
      "  decisions are likely until after Indonesia's elections on April\n",
      "  23, traders said.\n",
      "      Trade Minister Saleh said on Monday that Indonesia, as the\n",
      "  world's second largest producer of natural rubber, should\n",
      "  expand its rubber marketing effort and he hoped development of\n",
      "  the exchange would help this.\n",
      "      Nainggolan said that the exchange was trying to boost\n",
      "  overseas interest by building up contacts with end-users.\n",
      "      He said teams had already been to South Korea and Taiwan to\n",
      "  encourage direct use of the exchange, while a delegation would\n",
      "  also visit Europe, Mexico and some Latin American states to\n",
      "  encourage participation.\n",
      "      Officials say the infant exchange has made a good start\n",
      "  although trading in coffee has been disappointing.\n",
      "      Transactions in rubber between the start of trading in\n",
      "  April 1985 and December 1986 totalled 9,595 tonnes, worth 6.9\n",
      "  mln dlrs FOB, plus 184.3 mln rupiah for rubber delivered\n",
      "  locally, the latest exchange report said.\n",
      "       Trading in coffee in calendar 1986 amounted to only 1,905\n",
      "  tonnes in 381 lots, valued at 6.87 billion rupiah.\n",
      "       Total membership of the exchange is now nine brokers and\n",
      "  44 traders.\n",
      "  \n",
      "\n",
      "\n",
      "Fileid \"test/14840\" list of sentences\n",
      "[['INDONESIAN', 'COMMODITY', 'EXCHANGE', 'MAY', 'EXPAND', 'The', 'Indonesian', 'Commodity', 'Exchange', 'is', 'likely', 'to', 'start', 'trading', 'in', 'at', 'least', 'one', 'new', 'commodity', ',', 'and', 'possibly', 'two', ',', 'during', 'calendar', '1987', ',', 'exchange', 'chairman', 'Paian', 'Nainggolan', 'said', '.'], ['He', 'told', 'Reuters', 'in', 'a', 'telephone', 'interview', 'that', 'trading', 'in', 'palm', 'oil', ',', 'sawn', 'timber', ',', 'pepper', 'or', 'tobacco', 'was', 'being', 'considered', '.'], ...]\n",
      "\n",
      "Fileid \"test/14840\" list of words\n",
      "['INDONESIAN', 'COMMODITY', 'EXCHANGE', 'MAY', ...]\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire ici le code nécessaire.\n",
    "# Q1\n",
    "#print(len(reuters.fileids()))\n",
    "# Q2\n",
    "#print(len(reuters.sents()))\n",
    "# Q3\n",
    "#print(len(reuters.words()))\n",
    "# Q4\n",
    "#reuters.fileids()[:5]\n",
    "\n",
    "# Q5\n",
    "fileid_name = 'test/14840'\n",
    "\n",
    "print('Fileid \"{}\" raw text'.format(fileid_name))\n",
    "print(reuters.raw(fileid_name))\n",
    "\n",
    "print('Fileid \"{}\" list of sentences'.format(fileid_name))\n",
    "print(reuters.sents(fileid_name))\n",
    "print()\n",
    "print('Fileid \"{}\" list of words'.format(fileid_name))\n",
    "print(reuters.words(fileid_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Combien de fichiers (fileids) le corpus Reuters contient-il ?  \n",
    "\n",
    "Il y a 10788 `fileids` dans le corpus.\n",
    "\n",
    "> Combien de phrases le corpus contient-il ?\n",
    "\n",
    "Il y a 54716 phrases dans le corpus.\n",
    "\n",
    "> Combien de mots le corpus contient-il ?\n",
    "\n",
    "Il y a 1720901 mots dans le corpus.\n",
    "\n",
    "> Veuillez afficher 5 fileids de votre choix (les noms, pas les contenus)\n",
    "\n",
    "['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833']\n",
    "\n",
    "> Pour un fichier (fileid) de votre choix, veuillez afficher son texte brut, puis la liste de ses phrases, puis enfin la liste de ses mots (avec la tokenization de référence du corpus)\n",
    "\n",
    "Voir code ci-dessus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vous demande maintenant d'expérimenter avec un seul texte du corpus Reuters, pour en extraire les entités nommées.   Veuillez répondre aux questions suivantes.\n",
    "\n",
    "* À partir du texte brut (*raw*) d'une dépêche de votre choix, effectuez la segmentation en phrases, et affichez le nombre de phrases\n",
    "* Sur une phrase de votre choix, effectuez avec NLTK la tokenization, le POS tagging et la NER, et affichez le résultat. (Si la phrase ne contient pas d'entité nommée (*chunk*), veuillez en choisir une autre.)\n",
    "* Quel est le type d'objet que retourne `ne_chunk` ?\n",
    "* Quelle est l'effet de l'attribut `binary` (True ou False) dans l'appel de `nltk.ne_chunk` ?\n",
    "* Veuillez rassembler les entités nommées de la phrase en une seule liste, de la forme `[('MTBE', 'ORGANIZATION'), ('United States', 'GPE')]` (veuillez notamment joindre en une seule chaîne les mots des entités à plusieurs mots).\n",
    "\n",
    "Pour votre information, le `ne_chunk()` de NLTK annote les types suivants d'entités nommées : ORGANIZATION, PERSON, LOCATION, DATE, TIME, MONEY, PERCENT, FACILITY, GPE (= *geo-political entity*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_entities(chunks):\n",
    "    lchunks = []\n",
    "    for chunk in chunks:\n",
    "        # check if the current chunk is a named entity\n",
    "        if hasattr(chunk, 'label'):\n",
    "            word = ' '.join([c[0] for c in chunk])\n",
    "            lchunks.append((word, chunk.label()))\n",
    "\n",
    "    return lchunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen sentence:  INDONESIAN COMMODITY EXCHANGE MAY EXPAND\n",
      "  The Indonesian Commodity Exchange is\n",
      "  likely to start trading in at least one new commodity, and\n",
      "  possibly two, during calendar 1987, exchange chairman Paian\n",
      "  Nainggolan said.\n"
     ]
    }
   ],
   "source": [
    "# get the raw_text of the chosen fileid\n",
    "fileid = reuters.fileids()[6]\n",
    "raw_text = reuters.raw(fileid)\n",
    "\n",
    "# pick a sentence out of the fileid\n",
    "sent = nltk.tokenize.sent_tokenize(raw_text)[0]\n",
    "\n",
    "print('Chosen sentence: ', sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the chosen phrase\n",
    "words = nltk.tokenize.word_tokenize(sent)\n",
    "tagged_words = nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of ne_chunk:\n",
      "(GPE INDONESIAN/NNP)\n",
      "(ORGANIZATION COMMODITY/NNP)\n",
      "('EXCHANGE', 'NNP')\n",
      "('MAY', 'NNP')\n",
      "('EXPAND', 'NNP')\n",
      "('The', 'DT')\n",
      "(GPE Indonesian/NNP)\n",
      "('Commodity', 'NNP')\n",
      "('Exchange', 'NNP')\n",
      "('is', 'VBZ')\n",
      "('likely', 'JJ')\n",
      "('to', 'TO')\n",
      "('start', 'VB')\n",
      "('trading', 'NN')\n",
      "('in', 'IN')\n",
      "('at', 'IN')\n",
      "('least', 'JJS')\n",
      "('one', 'CD')\n",
      "('new', 'JJ')\n",
      "('commodity', 'NN')\n",
      "(',', ',')\n",
      "('and', 'CC')\n",
      "('possibly', 'RB')\n",
      "('two', 'CD')\n",
      "(',', ',')\n",
      "('during', 'IN')\n",
      "('calendar', 'NN')\n",
      "('1987', 'CD')\n",
      "(',', ',')\n",
      "('exchange', 'NN')\n",
      "('chairman', 'NN')\n",
      "(PERSON Paian/NNP Nainggolan/NNP)\n",
      "('said', 'VBD')\n",
      "('.', '.')\n"
     ]
    }
   ],
   "source": [
    "# get all the chunks of the chosen sentence\n",
    "chunks = nltk.ne_chunk(tagged_words)\n",
    "\n",
    "print('Output of ne_chunk:')\n",
    "for chunk in chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named entities:\n",
      "[('INDONESIAN', 'GPE'), ('COMMODITY', 'ORGANIZATION'), ('Indonesian', 'GPE'), ('Paian Nainggolan', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Named entities:\")\n",
    "print(get_named_entities(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary = False\n",
      "(S\n",
      "  (GPE INDONESIAN/NNP)\n",
      "  (ORGANIZATION COMMODITY/NNP)\n",
      "  EXCHANGE/NNP\n",
      "  MAY/NNP\n",
      "  EXPAND/NNP\n",
      "  The/DT\n",
      "  (GPE Indonesian/NNP)\n",
      "  Commodity/NNP\n",
      "  Exchange/NNP\n",
      "  is/VBZ\n",
      "  likely/JJ\n",
      "  to/TO\n",
      "  start/VB\n",
      "  trading/NN\n",
      "  in/IN\n",
      "  at/IN\n",
      "  least/JJS\n",
      "  one/CD\n",
      "  new/JJ\n",
      "  commodity/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  possibly/RB\n",
      "  two/CD\n",
      "  ,/,\n",
      "  during/IN\n",
      "  calendar/NN\n",
      "  1987/CD\n",
      "  ,/,\n",
      "  exchange/NN\n",
      "  chairman/NN\n",
      "  (PERSON Paian/NNP Nainggolan/NNP)\n",
      "  said/VBD\n",
      "  ./.)\n",
      "\n",
      "binary = True\n",
      "(S\n",
      "  (NE INDONESIAN/NNP)\n",
      "  COMMODITY/NNP\n",
      "  EXCHANGE/NNP\n",
      "  MAY/NNP\n",
      "  EXPAND/NNP\n",
      "  The/DT\n",
      "  (NE Indonesian/NNP Commodity/NNP Exchange/NNP)\n",
      "  is/VBZ\n",
      "  likely/JJ\n",
      "  to/TO\n",
      "  start/VB\n",
      "  trading/NN\n",
      "  in/IN\n",
      "  at/IN\n",
      "  least/JJS\n",
      "  one/CD\n",
      "  new/JJ\n",
      "  commodity/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  possibly/RB\n",
      "  two/CD\n",
      "  ,/,\n",
      "  during/IN\n",
      "  calendar/NN\n",
      "  1987/CD\n",
      "  ,/,\n",
      "  exchange/NN\n",
      "  chairman/NN\n",
      "  (NE Paian/NNP Nainggolan/NNP)\n",
      "  said/VBD\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "print(\"binary = False\")\n",
    "print(nltk.ne_chunk(tagged_words, binary=False))\n",
    "print()\n",
    "print(\"binary = True\")\n",
    "print(nltk.ne_chunk(tagged_words, binary=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Quel est le type d'objet que retourne ne_chunk ?\n",
    "\n",
    "Il retourne un objet de type `<class 'nltk.tree.Tree'>`.\n",
    "\n",
    "> Quelle est l'effet de l'attribut binary (True ou False) dans l'appel de nltk.ne_chunk ?\n",
    "\n",
    "Cet attribut va déterminer quel `treebank POS tagger` la fonction va utiliser. **True** = `english_ace_binary.pickle`, **False** = `english_ace_multiclass.pickle`.\n",
    "\n",
    "En comparant l'output de la fonction en changement la valeur de cet attribut, on peut voir que quand il est set a **True** la fonction va simplement indiquer si le mot et une entité nommé, mais ne va pas préciser son type (e.g. si c'est une organisation).\n",
    "\n",
    "E.g.\n",
    "\n",
    "|       | binary = False           | binary = True  |\n",
    "| ----- | :----------------------- | -------------- |\n",
    "| THAI  | (GPE THAI/NNP)           | (NE THAI/NNP)  |\n",
    "| TRADE | (ORGANIZATION TRADE/NNP) | TRADE/NNP      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Veuillez écrire une fonction, commençant par la ligne `def extract_named_entities(text):` qui retourne la liste des entités nommées avec leur type, à partir d'un texte donné (string).  Inspirez-vous de votre réponse à la dernière question ci-dessus.\n",
    "* Testez votre fonction sur le texte que vous avez utilisé ci-dessus.  \n",
    "* Observez vous des erreurs de détection (rappel ou précision) et/ou d'étiquetage ?  Merci d'en indiquer quelques-unes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire ici le code nécessaire.\n",
    "def extract_named_entities(text):\n",
    "    tagged_words = []    \n",
    "    for sent in nltk.tokenize.sent_tokenize(text):\n",
    "        words = nltk.tokenize.word_tokenize(sent)\n",
    "        tagged_words = tagged_words + nltk.pos_tag(words)\n",
    "\n",
    "    chunks = nltk.ne_chunk(tagged_words)\n",
    "    return get_named_entities(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('INDONESIAN', 'GPE'),\n",
       " ('COMMODITY', 'ORGANIZATION'),\n",
       " ('Indonesian', 'GPE'),\n",
       " ('Paian Nainggolan', 'PERSON'),\n",
       " ('Reuters', 'ORGANIZATION'),\n",
       " ('CPO', 'ORGANIZATION'),\n",
       " ('Trade', 'PERSON'),\n",
       " ('Rachmat Saleh', 'PERSON'),\n",
       " ('Nainggolan', 'PERSON'),\n",
       " ('FOB', 'ORGANIZATION'),\n",
       " ('Robusta', 'PERSON'),\n",
       " ('Indonesia', 'GPE'),\n",
       " ('Saleh', 'PERSON'),\n",
       " ('Indonesia', 'GPE'),\n",
       " ('Nainggolan', 'PERSON'),\n",
       " ('South Korea', 'GPE'),\n",
       " ('Taiwan', 'GPE'),\n",
       " ('Europe', 'GPE'),\n",
       " ('Mexico', 'GPE'),\n",
       " ('American', 'GPE'),\n",
       " ('FOB', 'ORGANIZATION'),\n",
       " ('Total', 'ORGANIZATION')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_named_entities(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Erreurs observées.\n",
    "\n",
    "Une erreur que l'on peut voir est que l'organisation `Indonesian Commodity Exchange` n'est pas reconnue comme organisation selon `ne_chunk`. La première fois que cette organisation apparaît, la fonction la sépare en **2** entité nommé `('INDONESIAN', 'GPE'), ('COMMODITY', 'ORGANIZATION')` et que les autres fois, il ne reconnaît qu `Indonesian` comment entité nommée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez parcourir tous les textes du corpus Reuters et collecter toutes les entités nommées dans une liste.  Créez ensuite une `FreqDist` et affichez les 30 NE les plus fréquentes avec leur nombre d'occurrences.  Combien de temps approximativement prend cette opération ?  (Suggestion : augmentez progressivement le nombre de fileids que vous traitez, pour estimer le temps total.)  Veuillez commenter le résultat obtenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ALL of the chunks out of the full corpus\n",
    "# /!\\ THIS TAKES A LONG TIME TO EXECUTE /!\\\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "nes = []\n",
    "for fileid in reuters.fileids():\n",
    "    raw = reuters.raw(fileid)\n",
    "    nes = nes + extract_named_entities(raw)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Combien de temps approximativement prend cette opération ?\n",
    "\n",
    "Cette opération a pris ~12 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire ici les commentaires sur le résultat.\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(nes)\n",
    "\n",
    "print('Most frequent chunks')\n",
    "print(fdist.most_common()[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quel est le nombre total de NE trouvées (occurrences pas nécessairement différentes) et quel est le nombre de NE différentes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire ici le code nécessaire pour répondre aux deux questions.\n",
    "print('Number of NEs: ', len(nes))\n",
    "l = list(dict.fromkeys(nes))\n",
    "print('Number of different NEs: ', len(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Évaluer la fonction de NER de NLTK sur les données CoNLL 2003\n",
    "\n",
    "À la conférence [CoNLL](https://www.clips.uantwerpen.be/pages/past-workshops) 2003, une des tâches compétitives consistait à tester des systèmes de NER sur l'anglais (voir [la description de la tâche et les scores obtenus](https://www.clips.uantwerpen.be/conll2003/ner/)).  Les ressources annotées ne sont pas disponibles via CoNLL, mais on peut en trouver [une copie sur le web](https://sourceforge.net/p/text-analysis/svn/1243/tree/text-analysis/trunk/Corpora/CoNLL/2003/) (une [autre copie](https://github.com/synalp/NER/tree/master/corpus/CoNLL-2003) est aussi disponible).  Les textes proviennent du [corpus Reuters](http://trec.nist.gov/data/reuters/reuters.html).  Pour mémoire, une autre source de données est le [corpus WikiNER](https://github.com/dice-group/FOX/tree/master/input/Wikiner).\n",
    "\n",
    "Le format d'annotation comprend 4 colonnes séparées par un espace.  Ce format ressemble au format \"conll\" que nous avons utilisé pour le *POS tagging* et le *parsing*.  Chaque ligne correspond à un mot, et une ligne vide sépare les phrases.  Sur chaque ligne, le 1er item est le mot, le 2e est le POS tag, le 3e est un tag qui indique le groupe syntaxique, et le 4e le tag qui indique l'entité nommée.  (À vous d'étudier ce tag plus en détail.)  Il y a des données d'entraînement (`eng.train`), et trois fichiers de test (`eng.testa`, `eng.testb` et `eng.testc`, le 2e ayant servi pour l'évaluation finale).\n",
    "\n",
    "**Travail demandé**\n",
    "\n",
    "Les questions qui suivent (inspirées des étapes de ce [tutoriel en ligne](https://pythonprogramming.net/testing-stanford-ner-taggers-for-accuracy/)) vous permettront d'estimer la \"justesse\" du NER de NLTK  sur les données CoNLL (seulement l'*accuracy*, pas le rappel et la précision)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Le premier objectif** est d'importer les données CoNLL 2003 dans ce notebook et adapter leur format pour qu'il soit comparable à celui de `nltk.ne_chunk()`, ce qui nécessite aussi la modification de l'output de cette fonction.\n",
    "\n",
    "En examinant les fichiers `eng.testa`, `eng.testb` et `eng.testc`, décrivez brièvement le format d'annotation CoNLL (2-3 phrases) et indiquez les types de NER annotés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaque ligne correspond à un mot, les phrases sont séparée par des lignes vides\n",
    "# Le format d'une ligne est: <mot> <POS> <Chunk> <Label>\n",
    "\n",
    "# O, I-ORG, I-LOC, I-MISC, I-PER, B-MISC, B-ORG, B-LOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez écrire une fonction qui ouvre un fichier CoNLL (p.ex. `eng.testa`) et crée deux listes :\n",
    "1. la liste des paires (token, pos_tag) que vous passerez plus tard à `ne_chunk()`;\n",
    "2. la liste des paires (token, ner_tag) où ner_tag est l'une des catégories de NER que vous avez indiquées plus haut.\n",
    "Ces listes seront stockées comme ci-dessous.  Appelez ensuite cette fonction sur les trois fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['eng.testa', 'eng.testb', 'eng.testc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conll2nltk(filename='eng.testa'):\n",
    "    with open(filename) as fd:\n",
    "        words_pos_tagged = []\n",
    "        words_ner_tagged = []\n",
    "\n",
    "        lines = fd.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if line == '':\n",
    "                continue\n",
    "\n",
    "            word_info = line.split(' ')\n",
    "            words_pos_tagged.append((word_info[0], word_info[1]))\n",
    "            # clean up conll ner tag\n",
    "            ner_tag = word_info[3][2:] if word_info[3] != 'O' else word_info[3]\n",
    "            words_ner_tagged.append((word_info[0], ner_tag))\n",
    "        \n",
    "        return (words_pos_tagged, words_ner_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez appliquer la fonction aux trois noms de fichier fournis.\n",
    "pos_tags = dict()\n",
    "ner_tags = dict()\n",
    "\n",
    "for f in filenames:\n",
    "    pos_tags[f], ner_tags[f] = conll2nltk(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Voici comment stocker les données dans une structure:\n",
    "test_data = dict()\n",
    "for f in filenames:\n",
    "    test_data[f] = dict()\n",
    "    test_data[f]['words'] = []\n",
    "    test_data[f]['keytags'] = [] # 'key' signifie correct\n",
    "    test_data[f]['reptags'] = [] # 'rep' pour réponse du système\n",
    "    \n",
    "    # add the words with chunks to the structure\n",
    "    for tag in ner_tags[f]:\n",
    "        test_data[f]['words'].append(tag[0])\n",
    "        test_data[f]['keytags'].append(tag[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Le second objectif** est de donner les mots à `ne_chunk()`, obtenir le résultat de la NER, et le stocker dans la même forme que l'annotation de référence (des paires de (token, TAG) pour tous les tokens).  Ces résultats seront ajoutés à la structure `test_data` dans le champ 'reptags' (pour \"response tags\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire ici le code pour les 3 datasets.\n",
    "reps = dict()\n",
    "for f in filenames:\n",
    "    reps[f] = []\n",
    "    for chunk in nltk.ne_chunk(pos_tags[f]):\n",
    "        ner_label = chunk.label() if hasattr(chunk, 'label') else 'O'\n",
    "        rep = []\n",
    "        if hasattr(chunk, 'label'):\n",
    "            rep = [(c[0], chunk.label()) for c in chunk]\n",
    "        else:\n",
    "            rep = [(chunk[0], 'O')]\n",
    "            \n",
    "        reps[f] = reps[f] + rep\n",
    "    \n",
    "    test_data[f]['reptags'] = list(map(lambda x: x[1], reps[f]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez vérifier, pour chaque fichier, que les listes 'keytags' et 'reptags' ont le même nombre de mots, en les affichant côte à côte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Veuillez écrire ici le code pour les 3 datasets.\n",
    "for f in filenames:\n",
    "    print(f)\n",
    "    print(\"Number of 'keytags': \", len(test_data[f]['keytags']))\n",
    "    print(\"Number of 'reptags': \", len(test_data[f]['reptags']))\n",
    "    print(\"keytags vs reptags\")\n",
    "    print(\"------------------\")\n",
    "    print(\"word\\t\\tkeytag\\t\\treptag\")\n",
    "    for i in range(len(test_data[f]['words'])):\n",
    "        print(\"{}\\t\\t{}\\t\\t{}\".format(test_data[f]['words'][i],test_data[f]['keytags'][i],test_data[f]['reptags'][i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Le 3e et dernier objectif** est de calculer la pourcentage d'étiquettes correctes dans les trois fichiers par rapport au nombre de mots de chacun.  \n",
    "\n",
    "Pour ce faire, remarquez que les étiquettes assignées par NLTK sont ORGANIZATION, PERSON, LOCATION, DATE, TIME, MONEY, PERCENT, FACILITY, GPE (= geo-political entity), alors que celles des fichiers CoNLL sont celles que vous avez indiquées en réponse plus haut.  Pour comptabiliser les réponses correctes, il faut d'abord définir une fonction appelée `compatible(n, c)` qui indique si deux étiquettes (l'une de NLTK, l'autre de CoNLL) sont conceptuellement identiques (c'est-à-dire qu'elles ont la même signification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez définir ici une fonction de comparaison des tags NER.\n",
    "def compatible(n, c):\n",
    "    compatibles = dict()\n",
    "    compatibles[\"O\"] = [\"O\"]\n",
    "    compatibles[\"ORG\"] = [\"ORGANIZATION\", \"FACILITY\"]\n",
    "    compatibles[\"LOC\"] = [\"LOCATION\", \"GPE\"]\n",
    "    compatibles[\"PER\"] = [\"PERSON\"]\n",
    "    compatibles[\"MISC\"] = [\"DATE\", \"TIME\", \"MONEY\", \"PERCENT\", \"GSP\"]\n",
    "    \n",
    "    return n in compatibles[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez définir ici une fonction qui compare deux listes de (mot, tag) et qui\n",
    "# retourne le pourcentage de (mot, tag) identiques selon la fonction \"compatible()\".\n",
    "def compare(a, b):\n",
    "    # check that the list are compatible\n",
    "    if len(a) != len(b):\n",
    "        raise Exception(\"Lists not compatible\")\n",
    "    compatibles = [compatible(a[i], b[i]) for i in range(len(a))]\n",
    "    return 100 * sum(compatibles) / len(compatibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in reps:\n",
    "    print(\"{}: {:.2f}%\".format(f, compare(test_data[f]['reptags'], test_data[f]['keytags'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note sur `nltk.ne_chunk()`.** Pour mémoire, signalons que le résultat de `nltk.ne_chunk()`, qui est un arbre, peut être transformé en une chaîne de caractères multi-lignes formatée selon les guidelines CoNLL grâce à la méthode `nltk.chunk.tree2conllstr()`.  Par ailleurs, pour comparer deux étiquetages de mots (listes de paires (mot, tag)), on peut utiliser directement la fonction `nltk.metrics.scores.accuracy` de NLTK, pour autant que les tags soient comparables avec `==`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarque finale\n",
    "Il est possible d'appliquer de la même façon [l'outil de NER avec CRF fourni par Stanford](https://nlp.stanford.edu/software/CRF-NER.html).  Les CRF, *Conditional Random Fields*, sont le modèle probabiliste qui est utilisé dans cet outil.\n",
    "\n",
    "Comme dans le cas du *POS tagger* CoreNLP de Stanford, on peut invoquer l'outil en ligne de commande (suivant les exemples fournis [ici](https://nlp.stanford.edu/software/CRF-NER.html#Starting) ou [ici](https://nlp.stanford.edu/software/crf-faq.shtml), notamment pour les [options de sortie](https://nlp.stanford.edu/software/crf-faq.shtml#j)).  Ou alors, on peut utiliser le [wrapper `StanfordNERTagger` de NLTK](http://www.nltk.org/api/nltk.tag.html?#nltk.tag.stanford.StanfordNERTagger).  On peut alors voir que les performances sont plus élevées que celles de `nltk.ne_chunk()`. \n",
    "\n",
    "Une [version plus élaborée de NER est fournie par Stanford dans le cadre de la boîte à outils CoreNLP](https://stanfordnlp.github.io/CoreNLP/ner.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du laboratoire 4\n",
    "\n",
    "Merci de nettoyer votre feuille, exécuter une dernière fois toutes les instructions, sauvegarder le résultat, et le soumettre sur Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
